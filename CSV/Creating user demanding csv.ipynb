{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7988515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'custom_data_with_faker.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Generate random headers\n",
    "num_columns = 20\n",
    "headers = [fake.word() for _ in range(num_columns)]\n",
    "\n",
    "# Generate random data types for each column\n",
    "data_types = ['random_int', 'name', 'address', 'date_time', 'pybool',\n",
    "              'random_element', 'pydecimal', 'random_digit', 'sentence', 'email', 'text',\n",
    "              'phone_number', 'city', 'state', 'country', 'user_name', 'color_name', 'iban', 'company']\n",
    "\n",
    "# Generate data based on data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for dt in data_types:\n",
    "        if dt == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif dt == 'random_float':\n",
    "            row.append(fake.random_float(min=0.1, max=10.0))\n",
    "        else:\n",
    "            row.append(getattr(fake, dt)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_faker.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f330a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter header for column 1: Name\n",
      "Enter header for column 2: Country\n",
      "Enter header for column 3: State\n",
      "Enter header for column 4: Phone \n",
      "Enter header for column 5: Pincode\n",
      "Enter header for column 6: Data\n",
      "Enter header for column 7: Email\n",
      "Enter header for column 8: Amount/\n",
      "Enter header for column 9: Discount\n",
      "Enter header for column 10: Total\n",
      "CSV file 'custom_data_with_user_input.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "\n",
    "# Generate random data types for each column\n",
    "data_types = ['random_int',  'name', 'address', 'date_time', 'pybool',\n",
    "              'random_element', 'pydecimal', 'random_digit', 'sentence', 'email', 'text',\n",
    "              'phone_number', 'city', 'state', 'country', 'user_name', 'color_name', 'iban', 'company']\n",
    "\n",
    "# Generate data based on data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for dt in data_types:\n",
    "        if dt == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif dt == 'random_float':\n",
    "            row.append(fake.random_float(min=0.1, max=10.0))\n",
    "        else:\n",
    "            row.append(getattr(fake, dt)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf3419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter header for column 1: Name\n",
      "Enter header for column 2: Country\n",
      "Enter header for column 3: State\n",
      "Enter header for column 4: Address\n",
      "Enter header for column 5: Phone \n",
      "Enter header for column 6: Email\n",
      "Enter header for column 7: Amount \n",
      "Enter header for column 8: Discount\n",
      "Enter header for column 9: Number of items\n",
      "Enter header for column 10: Total\n",
      "CSV file 'custom_data_with_user_input_and_nlp.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "# Initialize spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "data_type_mapping = {}\n",
    "\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "    \n",
    "    # Use spaCy to extract keywords related to data types\n",
    "    doc = nlp(header)\n",
    "    data_type_keywords = [token.text for token in doc if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\"]\n",
    "    \n",
    "    # Map extracted keywords to data types\n",
    "    inferred_data_type = \"random_element\"  # Default data type\n",
    "    for keyword in data_type_keywords:\n",
    "        if \"integer\" in keyword or \"number\" in keyword:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif \"float\" in keyword or \"decimal\" in keyword:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif \"date\" in keyword:\n",
    "            inferred_data_type = \"date_time\"\n",
    "        # Add more conditions for other data types\n",
    "    \n",
    "    data_type_mapping[header] = inferred_data_type\n",
    "\n",
    "# Generate data based on inferred data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for header in headers:\n",
    "        data_type = data_type_mapping[header]\n",
    "        if data_type == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif data_type == 'random_float':\n",
    "            row.append(fake.random_float(min=0.1, max=10.0))\n",
    "        else:\n",
    "            row.append(getattr(fake, data_type)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input_and_nlp.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb463aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "# Initialize spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "data_type_mapping = {}\n",
    "\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "    \n",
    "    # Use spaCy to extract keywords related to data types\n",
    "    doc = nlp(header)\n",
    "    data_type_keywords = [token.text.lower() for token in doc if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\"]\n",
    "    \n",
    "    # Map extracted keywords to data types\n",
    "    inferred_data_type = \"random_element\"  # Default data type\n",
    "    for keyword in data_type_keywords:\n",
    "        if keyword in [\n",
    "    \"Value\", \"Integer\", \"Numeric\", \"Digit\", \"Count\", \"Figure\", \"Numerical\",\n",
    "    \"Quantity\", \"Total\", \"Sum\", \"Amount\", \"Aggregate\", \"Tally\", \"Score\",\n",
    "    \"Magnitude\", \"Measurement\", \"Calculation\", \"Estimate\", \"Outcome\", \"Result\",\n",
    "    \"Data\", \"Point\", \"Mark\", \"Reading\", \"Rate\", \"Measure\", \"Portion\", \"Unit\",\n",
    "    \"Proportion\", \"Ratio\", \"Percent\", \"Fraction\", \"Division\", \"Segment\",\n",
    "    \"Section\", \"Component\", \"Element\", \"Part\", \"Quotient\", \"Remnant\",\n",
    "    \"Residue\", \"Excess\", \"Surplus\", \"Balance\", \"Margin\", \"Differential\",\n",
    "    \"Deviation\", \"Variance\", \"Spread\", \"Interval\", \"Range\", \"Extent\",\n",
    "    \"Depth\", \"Height\", \"Scale\", \"Volume\", \"Size\", \"Length\", \"Breadth\",\n",
    "    \"Width\", \"Diameter\", \"Circumference\", \"Area\", \"Perimeter\", \"Capacity\",\n",
    "    \"Load\", \"Weight\", \"Mass\", \"Force\", \"Pressure\", \"Rate\", \"Speed\",\n",
    "    \"Velocity\", \"Acceleration\", \"Frequency\", \"Amplitude\", \"Dimension\",\n",
    "    \"Order\", \"Sequence\", \"Arrangement\", \"Array\", \"Pattern\", \"Trend\",\n",
    "    \"Progression\", \"Gradation\", \"Increment\", \"Step\", \"Leap\", \"Hike\",\n",
    "    \"Rank\", \"Tier\", \"Level\", \"Order\", \"Sequence\", \"Set\", \"Array\",\n",
    "    \"Index\", \"Scale\", \"Range\", \"Depth\"]:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['phone']:\n",
    "            inferred_data_type = \"phone_number\"\n",
    "        elif keyword in ['email']:\n",
    "            inferred_data_type = \"email\"\n",
    "        # Add more conditions for other data types\n",
    "    \n",
    "    data_type_mapping[header] = inferred_data_type\n",
    "\n",
    "# Generate data based on inferred data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for header in headers:\n",
    "        data_type = data_type_mapping[header]\n",
    "        if data_type == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif data_type == 'phone_number':\n",
    "            row.append(fake.phone_number())\n",
    "        elif data_type == 'email':\n",
    "            row.append(fake.email())\n",
    "        else:\n",
    "            row.append(getattr(fake, data_type)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input_and_nlp.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66693a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lorem'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mword2number\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mw2n\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mw2n\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minflect\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlorem\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Initialize Faker instance\u001b[39;00m\n\u001b[1;32m      8\u001b[0m fake \u001b[38;5;241m=\u001b[39m Faker()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lorem'"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import csv\n",
    "import word2number.w2n as w2n\n",
    "import inflect\n",
    "import lorem\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Initialize inflect engine\n",
    "p = inflect.engine()\n",
    "\n",
    "# Generate a large number of placeholder keywords\n",
    "num_keywords = 10000\n",
    "placeholder_keywords = [lorem.word() for _ in range(num_keywords)]\n",
    "\n",
    "# Generate placeholder data types\n",
    "placeholder_data_types = ['random_int', 'random_float', 'name', 'address', 'date_time', 'pybool',\n",
    "                         'random_element', 'pydecimal', 'random_digit', 'sentence', 'email', 'text',\n",
    "                         'phone_number', 'city', 'state', 'country', 'user_name', 'color_name', 'iban', 'company']\n",
    "\n",
    "# Create a dictionary to map keywords to data types\n",
    "data_type_keywords = {keyword.lower(): fake.random_element(placeholder_data_types) for keyword in placeholder_keywords}\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "data_type_mapping = {}\n",
    "\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "    \n",
    "    # Extract words from the header\n",
    "    words = header.split()\n",
    "    \n",
    "    # Infer data type based on keywords\n",
    "    inferred_data_type = \"random_element\"  # Default data type\n",
    "    for word in words:\n",
    "        if word.lower() in data_type_keywords:\n",
    "            inferred_data_type = data_type_keywords[word.lower()]\n",
    "            break\n",
    "    \n",
    "    data_type_mapping[header] = inferred_data_type\n",
    "\n",
    "# Generate data based on inferred data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for header in headers:\n",
    "        data_type = data_type_mapping[header]\n",
    "        if data_type == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif data_type == 'random_float':\n",
    "            row.append(fake.random_float(min=0.1, max=10.0))\n",
    "        elif data_type == 'phone_number':\n",
    "            row.append(fake.phone_number())\n",
    "        elif data_type == 'email':\n",
    "            row.append(fake.email())\n",
    "        else:\n",
    "            row.append(getattr(fake, data_type)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input_and_enhanced_nlp_large.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990efa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize NER pipeline for data type recognition\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m ner_pipeline \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbmdz/bert-large-cased-finetuned-conll03-english\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize Faker instance\u001b[39;00m\n\u001b[1;32m      9\u001b[0m fake \u001b[38;5;241m=\u001b[39m Faker()\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/transformers/pipelines/__init__.py:807\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    806\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 807\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    808\u001b[0m         model,\n\u001b[1;32m    809\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[1;32m    810\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    811\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[1;32m    812\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    815\u001b[0m     )\n\u001b[1;32m    817\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    818\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/transformers/pipelines/base.py:219\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "# Initialize NER pipeline for data type recognition\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "data_type_mapping = {}\n",
    "\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "    \n",
    "    # Perform NER on the header to extract data type-related information\n",
    "    ner_results = ner_pipeline(header)\n",
    "    data_type_keywords = [entity['word'].lower() for entity in ner_results if entity['entity'] == 'MISC']\n",
    "    \n",
    "    # Map extracted keywords to data types\n",
    "    inferred_data_type = \"random_element\"  # Default data type\n",
    "    for keyword in data_type_keywords:\n",
    "        if keyword in ['number', 'amount', 'total', 'discount', 'items']:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['float']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['date', 'time']:\n",
    "            inferred_data_type = \"date_time\"\n",
    "        # Add more conditions for other data types\n",
    "    \n",
    "    data_type_mapping[header] = inferred_data_type\n",
    "\n",
    "# Generate data based on inferred data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for header in headers:\n",
    "        data_type = data_type_mapping[header]\n",
    "        if data_type == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif data_type == 'random_float':\n",
    "            row.append(fake.random_float(min=0.1, max=10.0))\n",
    "        else:\n",
    "            row.append(getattr(fake, data_type)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input_and_transformers.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab6589d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (143558552.py, line 136)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 136\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"CSV file '{csv_file_path}' generated successfully!\")B\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from faker import Faker\n",
    "import csv\n",
    "\n",
    "# Initialize spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "data_type_mapping = {}\n",
    "\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "    \n",
    "    # Use spaCy to extract keywords related to data types\n",
    "    doc = nlp(header)\n",
    "    data_type_keywords = [token.text.lower() for token in doc if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\"]\n",
    "    \n",
    "    # Map extracted keywords to data types\n",
    "    inferred_data_type = \"random_element\"  # Default data type\n",
    "    for keyword in data_type_keywords:\n",
    "        if keyword in [\n",
    "    \"Value\", \"Integer\", \"Numeric\", \"Digit\", \"Count\", \"Figure\", \"Numerical\",\n",
    "    \"Quantity\", \"Total\", \"Sum\", \"Amount\", \"Aggregate\", \"Tally\", \"Score\",\n",
    "    \"Magnitude\", \"Measurement\", \"Calculation\", \"Estimate\", \"Outcome\", \"Result\",\n",
    "    \"Data\", \"Point\", \"Mark\", \"Reading\", \"Rate\", \"Measure\", \"Portion\", \"Unit\",\n",
    "    \"Proportion\", \"Ratio\", \"Percent\", \"Fraction\", \"Division\", \"Segment\",\n",
    "    \"Section\", \"Component\", \"Element\", \"Part\", \"Quotient\", \"Remnant\",\n",
    "    \"Residue\", \"Excess\", \"Surplus\", \"Balance\", \"Margin\", \"Differential\",\n",
    "    \"Deviation\", \"Variance\", \"Spread\", \"Interval\", \"Range\", \"Extent\",\n",
    "    \"Depth\", \"Height\", \"Scale\", \"Volume\", \"Size\", \"Length\", \"Breadth\",\n",
    "    \"Width\", \"Diameter\", \"Circumference\", \"Area\", \"Perimeter\", \"Capacity\",\n",
    "    \"Load\", \"Weight\", \"Mass\", \"Force\", \"Pressure\", \"Rate\", \"Speed\",\n",
    "    \"Velocity\", \"Acceleration\", \"Frequency\", \"Amplitude\", \"Dimension\",\n",
    "    \"Order\", \"Sequence\", \"Arrangement\", \"Array\", \"Pattern\", \"Trend\",\n",
    "    \"Progression\", \"Gradation\", \"Increment\", \"Step\", \"Leap\", \"Hike\",\n",
    "    \"Rank\", \"Tier\", \"Level\", \"Order\", \"Sequence\", \"Set\", \"Array\",\n",
    "    \"Index\", \"Scale\", \"Range\", \"Depth\"]:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['phone']:\n",
    "            inferred_data_type = \"phone_number\"\n",
    "        elif keyword in ['email']:\n",
    "            inferred_data_type = \"email\"\n",
    "        elif keyword in ['decimal', 'float']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['date', 'time']:\n",
    "            inferred_data_type = \"date_time\"\n",
    "        elif keyword in ['phone']:\n",
    "            inferred_data_type = \"phone_number\"\n",
    "        elif keyword in ['email']:\n",
    "            inferred_data_type = \"email\"\n",
    "        elif keyword in ['name', 'first', 'last']:\n",
    "            inferred_data_type = \"first_name\"\n",
    "        elif keyword in ['address']:\n",
    "            inferred_data_type = \"address\"\n",
    "        elif keyword in ['text', 'description', 'comment']:\n",
    "            inferred_data_type = \"text\"\n",
    "        elif keyword in ['boolean', 'bool']:\n",
    "            inferred_data_type = \"pybool\"\n",
    "        elif keyword in ['currency', 'money']:\n",
    "            inferred_data_type = \"pydecimal\"\n",
    "        elif keyword in ['color']:\n",
    "            inferred_data_type = \"color_name\"\n",
    "        elif keyword in ['language', 'locale']:\n",
    "            inferred_data_type = \"language_code\"\n",
    "        elif keyword in ['company']:\n",
    "            inferred_data_type = \"company\"\n",
    "        elif keyword in ['url']:\n",
    "            inferred_data_type = \"url\"\n",
    "        elif keyword in ['credit', 'card']:\n",
    "            inferred_data_type = \"credit_card_number\"\n",
    "        # Add more conditions for other data types\n",
    "        elif keyword in ['quantity', 'stock', 'inventory']:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['weight', 'mass']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['score', 'rating']:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['percentage', 'percent']:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['temperature']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['duration', 'time']:\n",
    "            inferred_data_type = \"time_delta\"\n",
    "        elif keyword in ['age']:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['speed', 'velocity']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['volume']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['size']:\n",
    "            inferred_data_type = \"random_int\"\n",
    "        elif keyword in ['length']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['width']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['height']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['area']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        elif keyword in ['capacity']:\n",
    "            inferred_data_type = \"random_float\"\n",
    "        # Add more conditions for other data types\n",
    "    \n",
    "    data_type_mapping[header] = inferred_data_type\n",
    "\n",
    "# Generate data based on inferred data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for header in headers:\n",
    "        data_type = data_type_mapping[header]\n",
    "        if data_type == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif data_type == 'phone_number':\n",
    "            row.append(fake.phone_number())\n",
    "        elif data_type == 'email':\n",
    "            row.append(fake.email())\n",
    "        else:\n",
    "            row.append(getattr(fake, data_type)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input_and_nlp.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c08868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter header for column 1: Name\n",
      "Enter header for column 2: Age\n",
      "Enter header for column 3: Data\n",
      "Enter header for column 4: Number of item\n",
      "Enter header for column 5: Amount\n",
      "Enter header for column 6: Discount\n",
      "Enter header for column 7: Score\n",
      "Enter header for column 8: Email\n",
      "Enter header for column 9: Address\n",
      "Enter header for column 10: Total\n",
      "CSV file 'custom_data_with_user_input_and_nlp.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from faker import Faker\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Initialize spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Get user input for column headers\n",
    "num_columns = 10\n",
    "headers = []\n",
    "data_type_mapping = {}\n",
    "\n",
    "def infer_data_type(header):\n",
    "    data_type_keywords = [token.text.lower() for token in nlp(header) if token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\"]\n",
    "    \n",
    "    if any(re.match(r'(value|int|num|digit|count|figure|numerical|quantity|total|sum|amount|aggregate|tally|score|magnitude|measurement|calculation|estimate|outcome|result)', keyword) for keyword in data_type_keywords):\n",
    "        return \"random_int\"\n",
    "    elif any(re.match(r'(decimal|float)', keyword) for keyword in data_type_keywords):\n",
    "        return \"random_float\"\n",
    "    elif any(re.match(r'(date|time)', keyword) for keyword in data_type_keywords):\n",
    "        return \"date_time\"\n",
    "    elif any(re.match(r'(phone)', keyword) for keyword in data_type_keywords):\n",
    "        return \"phone_number\"\n",
    "    elif any(re.match(r'(email)', keyword) for keyword in data_type_keywords):\n",
    "        return \"email\"\n",
    "    # Add more conditions for other data types\n",
    "    \n",
    "    return \"random_element\"\n",
    "\n",
    "for i in range(num_columns):\n",
    "    header = input(f\"Enter header for column {i+1}: \")\n",
    "    headers.append(header)\n",
    "    inferred_data_type = infer_data_type(header)\n",
    "    data_type_mapping[header] = inferred_data_type\n",
    "\n",
    "# Generate data based on inferred data types using Faker\n",
    "num_rows = 10000\n",
    "data = []\n",
    "for _ in range(num_rows):\n",
    "    row = []\n",
    "    for header in headers:\n",
    "        data_type = data_type_mapping[header]\n",
    "        if data_type == 'random_int':\n",
    "            row.append(fake.random_int(min=1, max=100))\n",
    "        elif data_type == 'phone_number':\n",
    "            row.append(fake.phone_number())\n",
    "        elif data_type == 'email':\n",
    "            row.append(fake.email())\n",
    "        else:\n",
    "            row.append(getattr(fake, data_type)())\n",
    "    data.append(row)\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_file_path = 'custom_data_with_user_input_and_nlp.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4c2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smart CSV Generator!\n",
      "Please tell me what type of data you want to generate: Student test data\n",
      "How many rows do you want to generate? 1000\n",
      "Enter the name of the CSV file: student\n",
      "Sorry, I couldn't understand your request. Please try again.\n",
      "Please tell me what type of data you want to generate: student\n",
      "How many rows do you want to generate? 9000\n",
      "Enter the name of the CSV file: ashgf\n",
      "Sorry, I couldn't understand your request. Please try again.\n",
      "Please tell me what type of data you want to generate: exit\n",
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define data types and corresponding generators\n",
    "data_generators = {\n",
    "    \"name\": fake.name,\n",
    "    \"age\": lambda: fake.random_int(min=18, max=60),\n",
    "    \"address\": fake.address,\n",
    "    \"email\": fake.email,\n",
    "    \"phone\": fake.phone_number,\n",
    "    \"job\": fake.job,\n",
    "    \"company\": fake.company,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"credit_card\": fake.credit_card_number,\n",
    "    \"country\": fake.country,\n",
    "    \"color\": fake.hex_color,\n",
    "    \"username\": fake.user_name,\n",
    "    \"domain\": fake.domain_name,\n",
    "    \"ipv4\": fake.ipv4,\n",
    "    \"ipv6\": fake.ipv6,\n",
    "    \"url\": fake.url,\n",
    "    \"isbn\": fake.isbn13,\n",
    "    \"word\": fake.word,\n",
    "    \"paragraph\": fake.paragraph,\n",
    "    \"sentence\": fake.sentence,\n",
    "    \"boolean\": lambda: fake.random_element(elements=('True', 'False')),\n",
    "    \"latitude\": fake.latitude,\n",
    "    \"longitude\": fake.longitude,\n",
    "    \"ssn\": fake.ssn,\n",
    "    \"timezone\": fake.timezone(),\n",
    "    \"language\": fake.language_code,\n",
    "    \"currency\": fake.currency_code,\n",
    "    # Add more data types and generators\n",
    "}\n",
    "\n",
    "def generate_data(intent, num_rows):\n",
    "    if intent in data_generators:\n",
    "        data = [(data_generators[intent](),) for _ in range(num_rows)]\n",
    "    else:\n",
    "        data = []\n",
    "    return data\n",
    "\n",
    "def create_csv(file_name, data):\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Smart CSV Generator!\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"Please tell me what type of data you want to generate: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Exiting the program.\")\n",
    "            break\n",
    "        \n",
    "        num_rows = int(input(\"How many rows do you want to generate? \"))\n",
    "        file_name = input(\"Enter the name of the CSV file: \")\n",
    "        \n",
    "        # Perform intent recognition using regular expressions\n",
    "        intent = None\n",
    "        for data_type in data_generators.keys():\n",
    "            if re.search(r'\\b' + re.escape(data_type) + r'\\b', user_input, re.IGNORECASE):\n",
    "                intent = data_type\n",
    "                break\n",
    "        \n",
    "        if intent:\n",
    "            data = generate_data(intent, num_rows)\n",
    "            if data:\n",
    "                create_csv(file_name + \".csv\", data)\n",
    "                print(f\"CSV file '{file_name}.csv' generated successfully!\")\n",
    "            else:\n",
    "                print(\"I don't have a generator for that data type yet.\")\n",
    "        else:\n",
    "            print(\"Sorry, I couldn't understand your request. Please try again.\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9242a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smart CSV Generator!\n",
      "Enter the name of the CSV file: ashb\n",
      "How many rows do you want to generate? 10\n",
      "How many columns (data types) do you want? 3\n",
      "Enter the header for column 1: Name\n",
      "Enter the data type for column 1 (e.g., marks, age, address): name\n",
      "Enter the header for column 2: Age\n",
      "Enter the data type for column 2 (e.g., marks, age, address): age\n",
      "Enter the header for column 3: Marks\n",
      "Enter the data type for column 3 (e.g., marks, age, address): marks\n",
      "CSV file 'ashb.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define data types and corresponding generators\n",
    "data_generators = {\n",
    "    \"name\": fake.name,\n",
    "    \"age\": lambda: fake.random_int(min=18, max=60),\n",
    "    \"address\": fake.address,\n",
    "    \"email\": fake.email,\n",
    "    \"phone\": fake.phone_number,\n",
    "    \"job\": fake.job,\n",
    "    \"company\": fake.company,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"credit_card\": fake.credit_card_number,\n",
    "    \"country\": fake.country,\n",
    "    \"color\": fake.hex_color,\n",
    "    \"username\": fake.user_name,\n",
    "    \"domain\": fake.domain_name,\n",
    "    \"ipv4\": fake.ipv4,\n",
    "    \"ipv6\": fake.ipv6,\n",
    "    \"url\": fake.url,\n",
    "    \"isbn\": fake.isbn13,\n",
    "    \"word\": fake.word,\n",
    "    \"paragraph\": fake.paragraph,\n",
    "    \"sentence\": fake.sentence,\n",
    "    \"boolean\": lambda: fake.random_element(elements=('True', 'False')),\n",
    "    \"latitude\": fake.latitude,\n",
    "    \"longitude\": fake.longitude,\n",
    "    \"ssn\": fake.ssn,\n",
    "    \"timezone\": fake.timezone(),\n",
    "    \"language\": fake.language_code,\n",
    "    \"currency\": fake.currency_code,\n",
    "    \"marks\": lambda: fake.random_int(min=0, max=100),  # Add marks data generator\n",
    "}\n",
    "\n",
    "def generate_data(data_types, num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        row = [data_generators[data_type]() for data_type in data_types]\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def assign_grade(marks):\n",
    "    if 90 <= marks <= 100:\n",
    "        return \"A\"\n",
    "    elif 80 <= marks < 90:\n",
    "        return \"B\"\n",
    "    elif 70 <= marks < 80:\n",
    "        return \"C\"\n",
    "    elif 60 <= marks < 70:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"F\"\n",
    "\n",
    "def create_csv(file_name, headers, data):\n",
    "    with open(file_name + \".csv\", 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Smart CSV Generator!\")\n",
    "    \n",
    "    file_name = input(\"Enter the name of the CSV file: \")\n",
    "    num_rows = int(input(\"How many rows do you want to generate? \"))\n",
    "    num_columns = int(input(\"How many columns (data types) do you want? \"))\n",
    "    \n",
    "    headers = []\n",
    "    data_types = []\n",
    "    for _ in range(num_columns):\n",
    "        header = input(f\"Enter the header for column {_ + 1}: \")\n",
    "        headers.append(header)\n",
    "        data_type = input(f\"Enter the data type for column {_ + 1} (e.g., marks, age, address): \")\n",
    "        data_types.append(data_type.strip())\n",
    "    \n",
    "    data = generate_data(data_types, num_rows)\n",
    "    \n",
    "    for row in data:\n",
    "        marks = row[data_types.index(\"marks\")]  # Retrieve marks value\n",
    "        grade = assign_grade(marks)\n",
    "        row.append(grade)\n",
    "    \n",
    "    headers.append(\"grade\")\n",
    "    create_csv(file_name, headers, data)\n",
    "    print(f\"CSV file '{file_name}.csv' generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7980ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smart CSV Generator!\n",
      "Enter the name of the CSV file: asjcb\n",
      "How many rows do you want to generate? 100\n",
      "How many columns (data types) do you want? 5\n",
      "Enter the header for column 1: name\n",
      "Enter the data type for column 1 (e.g., marks, amount, discounts): name\n",
      "Enter the header for column 2: age\n",
      "Enter the data type for column 2 (e.g., marks, amount, discounts): age\n",
      "Enter the header for column 3: address\n",
      "Enter the data type for column 3 (e.g., marks, amount, discounts): address\n",
      "Enter the header for column 4: amount\n",
      "Enter the data type for column 4 (e.g., marks, amount, discounts): amount\n",
      "Enter the header for column 5: discount\n",
      "Enter the data type for column 5 (e.g., marks, amount, discounts): discount\n",
      "Do you want to add a new column based on mathematical operation? (yes/no): yes\n",
      "Enter the header for the new column: total\n",
      "Enter the data type for the new column (e.g., float, int, etc.): float\n",
      "Enter the formula for the new column (e.g., amount - discounts): amount - discount\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 119\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m generated successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[5], line 107\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m row_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, data_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_types):\n\u001b[0;32m--> 107\u001b[0m     row_data[data_type] \u001b[38;5;241m=\u001b[39m row[j]\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(formula, row_data)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define data types and corresponding generators\n",
    "data_generators = {\n",
    "    # ... (other data types and generators)\n",
    "    \"name\": fake.name,\n",
    "    \"age\": lambda: fake.random_int(min=18, max=60),\n",
    "    \"address\": fake.address,\n",
    "    \"email\": fake.email,\n",
    "    \"phone\": fake.phone_number,\n",
    "    \"job\": fake.job,\n",
    "    \"company\": fake.company,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"credit_card\": fake.credit_card_number,\n",
    "    \"country\": fake.country,\n",
    "    \"color\": fake.hex_color,\n",
    "    \"username\": fake.user_name,\n",
    "    \"domain\": fake.domain_name,\n",
    "    \"ipv4\": fake.ipv4,\n",
    "    \"ipv6\": fake.ipv6,\n",
    "    \"url\": fake.url,\n",
    "    \"isbn\": fake.isbn13,\n",
    "    \"word\": fake.word,\n",
    "    \"paragraph\": fake.paragraph,\n",
    "    \"sentence\": fake.sentence,\n",
    "    \"boolean\": lambda: fake.random_element(elements=('True', 'False')),\n",
    "    \"latitude\": fake.latitude,\n",
    "    \"longitude\": fake.longitude,\n",
    "    \"ssn\": fake.ssn,\n",
    "    \"timezone\": fake.timezone(),\n",
    "    \"language\": fake.language_code,\n",
    "    \"currency\": fake.currency_code,\n",
    "    \"marks\": lambda: fake.random_int(min=0, max=100),\n",
    "    \"amount\": lambda: round(fake.random.uniform(a=10, b=50000), 2),\n",
    "    \"discount\": lambda: fake.random.uniform(a=0, b=80)\n",
    "}\n",
    "\n",
    "def generate_data(data_types, num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        row = [data_generators[data_type]() for data_type in data_types]\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "# def assign_grade(marks):\n",
    "#     if 90 <= marks <= 100:\n",
    "#         return \"A\"\n",
    "#     elif 80 <= marks < 90:\n",
    "#         return \"B\"\n",
    "#     elif 70 <= marks < 80:\n",
    "#         return \"C\"\n",
    "#     elif 60 <= marks < 70:\n",
    "#         return \"D\"\n",
    "#     else:\n",
    "#         return \"F\"\n",
    "\n",
    "def create_csv(file_name, headers, data):\n",
    "    with open(file_name + \".csv\", 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Smart CSV Generator!\")\n",
    "    \n",
    "    file_name = input(\"Enter the name of the CSV file: \")\n",
    "    num_rows = int(input(\"How many rows do you want to generate? \"))\n",
    "    num_columns = int(input(\"How many columns (data types) do you want? \"))\n",
    "    \n",
    "    headers = []\n",
    "    data_types = []\n",
    "    for _ in range(num_columns):\n",
    "        header = input(f\"Enter the header for column {_ + 1}: \")\n",
    "        headers.append(header)\n",
    "        data_type = input(f\"Enter the data type for column {_ + 1} (e.g., marks, amount, discounts): \")\n",
    "        data_types.append(data_type.strip())\n",
    "    \n",
    "    data = generate_data(data_types, num_rows)\n",
    "    \n",
    "#     for row in data:\n",
    "#         marks = row[data_types.index(\"marks\")]  # Retrieve marks value\n",
    "#         grade = assign_grade(marks)\n",
    "#         row.append(grade)\n",
    "    \n",
    "#     headers.append(\"grade\")\n",
    "    \n",
    "    while True:\n",
    "        add_column = input(\"Do you want to add a new column based on mathematical operation? (yes/no): \")\n",
    "        \n",
    "        if add_column.lower() == \"no\":\n",
    "            break\n",
    "        \n",
    "        new_header = input(\"Enter the header for the new column: \")\n",
    "        new_data_type = input(\"Enter the data type for the new column (e.g., float, int, etc.): \")\n",
    "        formula = input(\"Enter the formula for the new column (e.g., amount - discounts): \")\n",
    "        \n",
    "        data_types.append(new_data_type)\n",
    "        headers.append(new_header)\n",
    "        \n",
    "        for i in range(num_rows):\n",
    "            row = data[i]\n",
    "            row_data = {}\n",
    "            for j, data_type in enumerate(data_types):\n",
    "                row_data[data_type] = row[j]\n",
    "            \n",
    "            try:\n",
    "                new_value = eval(formula, row_data)\n",
    "                row.append(new_value)\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating formula: {e}\")\n",
    "    \n",
    "    create_csv(file_name, headers, data)\n",
    "    print(f\"CSV file '{file_name}.csv' generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f68d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smart CSV Generator!\n",
      "Enter the name of the CSV file: jhvds\n",
      "How many rows do you want to generate? 100\n",
      "How many columns (data types) do you want? 3\n",
      "Enter the header for column 1: name\n",
      "Enter the data type for column 1 (e.g., marks, amount, discount): name\n",
      "Enter the header for column 2: amount\n",
      "Enter the data type for column 2 (e.g., marks, amount, discount): amount\n",
      "Enter the header for column 3: discount\n",
      "Enter the data type for column 3 (e.g., marks, amount, discount): discount\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "3 columns passed, passed data had 4 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/pandas/core/internals/construction.py:934\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/pandas/core/internals/construction.py:981\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    982\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    984\u001b[0m     )\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 3 columns passed, passed data had 4 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m generated successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[5], line 71\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m data \u001b[38;5;241m=\u001b[39m generate_data(data_types, num_rows)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Create a DataFrame using pandas\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     add_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo you want to add a new column based on mathematical operation? (yes/no): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/pandas/core/frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 782\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         data,\n\u001b[1;32m    786\u001b[0m         columns,\n\u001b[1;32m    787\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    788\u001b[0m         dtype,\n\u001b[1;32m    789\u001b[0m     )\n\u001b[1;32m    790\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    791\u001b[0m         arrays,\n\u001b[1;32m    792\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    796\u001b[0m     )\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/pandas/core/internals/construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 498\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    499\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/pandas/core/internals/construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    837\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    838\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 840\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/Desktop/College/Third Sem/Data Analatics/CSV/env/lib/python3.11/site-packages/pandas/core/internals/construction.py:937\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    940\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 3 columns passed, passed data had 4 columns"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define data types and corresponding generators\n",
    "data_generators = {\n",
    "    # ... (other data types and generators)\n",
    "    \"name\": fake.name,\n",
    "    \"age\": lambda: fake.random_int(min=18, max=60),\n",
    "    \"address\": fake.address,\n",
    "    \"email\": fake.email,\n",
    "    \"phone\": fake.phone_number,\n",
    "    \"job\": fake.job,\n",
    "    \"company\": fake.company,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"credit_card\": fake.credit_card_number,\n",
    "    \"country\": fake.country,\n",
    "    \"color\": fake.hex_color,\n",
    "    \"username\": fake.user_name,\n",
    "    \"domain\": fake.domain_name,\n",
    "    \"ipv4\": fake.ipv4,\n",
    "    \"ipv6\": fake.ipv6,\n",
    "    \"url\": fake.url,\n",
    "    \"isbn\": fake.isbn13,\n",
    "    \"word\": fake.word,\n",
    "    \"paragraph\": fake.paragraph,\n",
    "    \"sentence\": fake.sentence,\n",
    "    \"boolean\": lambda: fake.random_element(elements=('True', 'False')),\n",
    "    \"latitude\": fake.latitude,\n",
    "    \"longitude\": fake.longitude,\n",
    "    \"ssn\": fake.ssn,\n",
    "    \"timezone\": fake.timezone(),\n",
    "    \"language\": fake.language_code,\n",
    "    \"currency\": fake.currency_code,\n",
    "    \"marks\": lambda: fake.random_int(min=0, max=100),\n",
    "    \"amount\": lambda: round(fake.random.uniform(a=10, b=50000), 2),\n",
    "    \"discount\": lambda: fake.random.uniform(a=0, b=80)\n",
    "}\n",
    "\n",
    "\n",
    "def generate_data(data_types, num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        row = [data_generators[data_type]() for data_type in data_types]\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Smart CSV Generator!\")\n",
    "    \n",
    "    file_name = input(\"Enter the name of the CSV file: \")\n",
    "    num_rows = int(input(\"How many rows do you want to generate? \"))\n",
    "    num_columns = int(input(\"How many columns (data types) do you want? \"))\n",
    "    \n",
    "    headers = []\n",
    "    data_types = []\n",
    "    for _ in range(num_columns):\n",
    "        header = input(f\"Enter the header for column {_ + 1}: \")\n",
    "        headers.append(header)\n",
    "        data_type = input(f\"Enter the data type for column {_ + 1} (e.g., marks, amount, discount): \")\n",
    "        data_types.append(data_type.strip())\n",
    "    \n",
    "    # Include the \"marks\" data type\n",
    "    data_types.append(\"marks\")\n",
    "    \n",
    "    data = generate_data(data_types, num_rows)\n",
    "    \n",
    "    # Create a DataFrame using pandas\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    while True:\n",
    "        add_column = input(\"Do you want to add a new column based on mathematical operation? (yes/no): \")\n",
    "        \n",
    "        if add_column.lower() == \"no\":\n",
    "            break\n",
    "        \n",
    "        new_header = input(\"Enter the header for the new column: \")\n",
    "        new_formula = input(\"Enter the formula for the new column (e.g., amount - discount): \")\n",
    "        \n",
    "        try:\n",
    "            new_column = df.eval(new_formula)\n",
    "            df[new_header] = new_column\n",
    "            print(\"New column added successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding new column: {e}\")\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(file_name + \".csv\", index=False)\n",
    "    print(f\"CSV file '{file_name}.csv' generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a19218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smart CSV Generator!\n",
      "Enter the name of the CSV file: sdlbv\n",
      "How many rows do you want to generate? 100\n",
      "How many columns (data types) do you want? 4\n",
      "Enter the header for column 1: score\n",
      "Enter the data type for column 1 (e.g., marks, age, address): score\n",
      "Enter the minimum value for random_int: 100\n",
      "Enter the maximum value for random_int: 1000\n",
      "Enter the header for column 2: number of item\n",
      "Enter the data type for column 2 (e.g., marks, age, address): number of \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def get_random_int_range():\n",
    "    min_value = int(input(\"Enter the minimum value for random_int: \"))\n",
    "    max_value = int(input(\"Enter the maximum value for random_int: \"))\n",
    "    return min_value, max_value\n",
    "\n",
    "data_generators = {\n",
    "    \"name\": fake.name,\n",
    "    \"age\": lambda: fake.random_int(min=18, max=80),\n",
    "    \"address\": fake.address,\n",
    "    \"email\": fake.email,\n",
    "    \"phone\": fake.phone_number,\n",
    "    \"job\": fake.job,\n",
    "    \"company\": fake.company,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"credit_card\": fake.credit_card_number,\n",
    "    \"country\": fake.country,\n",
    "    \"color\": fake.hex_color,\n",
    "    \"username\": fake.user_name,\n",
    "    \"domain\": fake.domain_name,\n",
    "    \"ipv4\": fake.ipv4,\n",
    "    \"ipv6\": fake.ipv6,\n",
    "    \"url\": fake.url,\n",
    "    \"isbn\": fake.isbn13,\n",
    "    \"word\": fake.word,\n",
    "    \"paragraph\": fake.paragraph,\n",
    "    \"sentence\": fake.sentence,\n",
    "    \"boolean\": lambda: fake.random_element(elements=('True', 'False')),\n",
    "    \"latitude\": fake.latitude,\n",
    "    \"longitude\": fake.longitude,\n",
    "    \"ssn\": fake.ssn,\n",
    "    \"timezone\": fake.timezone(),\n",
    "    \"language\": fake.language_code,\n",
    "    \"currency\": fake.currency_code,\n",
    "    \"score\": lambda :fake.random_int(min=0),\n",
    "    \"quantity\": lambda :fake.random_int(min=0),\n",
    "    \"value\":lambda : fake.random_int(min = 0),\n",
    "    \"tally\": lambda  :fake.random_int(),\n",
    "    \"total\": lambda :fake.random_int(),\n",
    "    \"count\": lambda :fake.random_int(),\n",
    "    \"sum\": lambda :fake.random_int(),\n",
    "    \"rate\": lambda :fake.random_int(),\n",
    "    \"measurement\":lambda : fake.random_int(),\n",
    "    \"digits\": lambda :fake.random_int(),\n",
    "    \"estimate\": lambda :fake.random_int(),\n",
    "    \"metric\": lambda :fake.random_int(),\n",
    "    \"numerical\": lambda :fake.random_int(),\n",
    "    \"portion\" : lambda :fake.random_int(),\n",
    "    \"magnitude\" : lambda :fake.random_int(),\n",
    "    \"index\" : lambda :fake.random_int(),\n",
    "    \"volume\": lambda :fake.random_int(),\n",
    "    \"number of\": lambda :fake.random_int(min = 0 , max = 200),\n",
    "    \"amount\":lambda : fake.random_int(),\n",
    "    \"discount\" : lambda: fake.random_int(min=5 , max = 90)\n",
    "}\n",
    "\n",
    "def generate_data(data_types, num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        row = []\n",
    "        for data_type in data_types:\n",
    "            if data_type in data_generators:\n",
    "                if data_type in [\"score\", \"quantity\", \"value\"]:\n",
    "                    min_value, max_value = get_random_int_range()\n",
    "                    row.append(fake.random_int(min=min_value, max=max_value))\n",
    "                else:\n",
    "                    row.append(data_generators[data_type]())\n",
    "            else:\n",
    "                print(f\"Invalid data type: {data_type}\")\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def create_csv(file_name, headers, data):\n",
    "    with open(file_name + \".csv\", 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Smart CSV Generator!\")\n",
    "    \n",
    "    file_name = input(\"Enter the name of the CSV file: \")\n",
    "    num_rows = int(input(\"How many rows do you want to generate? \"))\n",
    "    num_columns = int(input(\"How many columns (data types) do you want? \"))\n",
    "    \n",
    "    headers = []\n",
    "    data_types = []\n",
    "    for _ in range(num_columns):\n",
    "        header = input(f\"Enter the header for column {_ + 1}: \")\n",
    "        headers.append(header)\n",
    "        data_type = input(f\"Enter the data type for column {_ + 1} (e.g., marks, age, address): \")\n",
    "        data_types.append(data_type.strip())\n",
    "        \n",
    "        if data_type in [\"score\", \"quantity\", \"value\"]:\n",
    "            min_value, max_value = get_random_int_range()\n",
    "            data_generators[data_type] = lambda: fake.random_int(min=min_value, max=max_value)\n",
    "    \n",
    "    data = generate_data(data_types, num_rows)\n",
    "\n",
    "    create_csv(file_name, headers, data)\n",
    "    print(f\"CSV file '{file_name}.csv' generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e311e912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth Year: <bound method Provider.year of <faker.providers.date_time.en_US.Provider object at 0x121c21150>>\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_birth_year():\n",
    "    # birth_date = fake.date_of_birth()\n",
    "    birth_year = fake.year\n",
    "    return birth_year\n",
    "\n",
    "# Example usage\n",
    "birth_year = generate_birth_year()\n",
    "print(\"Birth Year:\", birth_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173ae80-7ff8-4831-926e-645da5f24073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09aff7-b2cb-47ec-a12e-3478c42c26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Smart CSV Generator!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the CSV file:  SAYAN\n",
      "How many rows do you want to generate?  11\n",
      "How many columns (data types) do you want?  12\n",
      "Enter the header for column 1:  DEBNATH\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def get_random_int_range():\n",
    "    min_value = int(input(\"Enter the minimum value for random_int: \"))\n",
    "    max_value = int(input(\"Enter the maximum value for random_int: \"))\n",
    "    return min_value, max_value\n",
    "    \n",
    "def get_random_float_range():\n",
    "    min_value_f = float(input(\"Enter the minimum value for random_float: \"))\n",
    "    max_value_f = float(input(\"Enter the maximum value for random_float: \"))\n",
    "    return random.uniform(min_value_f, max_value_f)\n",
    "    \n",
    "def get_date_range():\n",
    "    from_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "    to_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "    return from_date, to_date\n",
    "\n",
    "data_generators = {\n",
    "    \"name\": fake.name,\n",
    "    \"first name\": fake.first_name,\n",
    "    \"last name\": fake.last_name,\n",
    "    \"age\": lambda: fake.random_int(min=18, max=80),\n",
    "    \"address\": fake.address,\n",
    "    \"email\": fake.email,\n",
    "    \"phone\": fake.phone_number,\n",
    "    \"job\": fake.job,\n",
    "    \"company\": fake.company,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"credit_card\": fake.credit_card_number,\n",
    "    \"country\": fake.country,\n",
    "    \"color\": fake.hex_color,\n",
    "    \"username\": fake.user_name,\n",
    "    \"domain\": fake.domain_name,\n",
    "    \"ipv4\": fake.ipv4,\n",
    "    \"ipv6\": fake.ipv6,\n",
    "    \"url\": fake.url,\n",
    "    \"date\": fake.date_this_decade,\n",
    "    \"year\": lambda: fake.date_this_decade().year,  # Separate generator for year\n",
    "    \"isbn\": fake.isbn13,\n",
    "    \"word\": fake.word,\n",
    "    \"paragraph\": fake.paragraph,\n",
    "    \"sentence\": fake.sentence,\n",
    "    \"boolean\": lambda: fake.random_element(elements=('True', 'False')),\n",
    "    \"job type\": lambda: fake.random_element(elements=('Full Time', 'Part Time','Working Student',\"Contract\", \"Freelance\")),\n",
    "    \"gender\": lambda: fake.random_element(elements=('Male', 'Female')),\n",
    "    \"fule type\":lambda : fake.random_element(elements=('Petrol (Gasoline)' , 'Diesel')),\n",
    "    \"latitude\": fake.latitude,\n",
    "    \"longitude\": fake.longitude,\n",
    "    \"ssn\": fake.ssn,\n",
    "    \"timezone\": fake.timezone(),\n",
    "    \"language\": fake.language_code,\n",
    "    \"currency\": fake.currency_code,\n",
    "    \"score\": lambda :fake.random_int(min=0),\n",
    "    \"quantity\": lambda :fake.random_int(min=0),\n",
    "    \"value\":lambda : fake.random_int(min = 0),\n",
    "    \"tally\": lambda  :fake.random_int(),\n",
    "    \"total\": lambda :fake.random_int(),\n",
    "    \"count\": lambda :fake.random_int(),\n",
    "    \"sum\": lambda :fake.random_int(),\n",
    "    \"rate\": lambda :fake.random_float(),        # rating \n",
    "    \"measurement\":lambda : fake.random_int(),\n",
    "    \"digits\": lambda :fake.random_int(),\n",
    "    \"estimate\": lambda :fake.random_int(),\n",
    "    \"metric\": lambda :fake.random_int(),\n",
    "    \"numerical\": lambda :fake.random_int(),\n",
    "    \"portion\" : lambda :fake.random_int(),\n",
    "    \"magnitude\" : lambda :fake.random_int(),\n",
    "    \"index\" : lambda :fake.random_int(),\n",
    "    \"volume\": lambda :fake.random_int(),\n",
    "    \"number of\": lambda :fake.random_int(),\n",
    "    \"amount\":lambda : fake.random_int(),\n",
    "    \"discount\" : lambda: fake.random_int()\n",
    "}\n",
    "\n",
    "def generate_data(data_types, num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        row = []\n",
    "        for data_type in data_types:\n",
    "            if data_type in data_generators:\n",
    "                if data_type == \"date\":\n",
    "                    from_date, to_date = get_date_range()\n",
    "                    row.append(fake.date_between_dates(date_start=from_date, date_end=to_date))\n",
    "                else:\n",
    "                    row.append(data_generators[data_type]())\n",
    "            else:\n",
    "                print(f\"Invalid data type: {data_type}\")\n",
    "        data.append(row)\n",
    "    return data\n",
    "\n",
    "def create_csv(file_name, headers, data):\n",
    "    with open(file_name + \".csv\", 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome to Smart CSV Generator!\")\n",
    "    \n",
    "    file_name = input(\"Enter the name of the CSV file: \")\n",
    "    num_rows = int(input(\"How many rows do you want to generate? \"))\n",
    "    num_columns = int(input(\"How many columns (data types) do you want? \"))\n",
    "    \n",
    "    headers = []\n",
    "    data_types = []\n",
    "    for _ in range(num_columns):\n",
    "        header = input(f\"Enter the header for column {_ + 1}: \")\n",
    "        headers.append(header)\n",
    "        data_type = input(f\"Enter the data type for column {_ + 1} (e.g., marks, age, address): \")\n",
    "        data_types.append(data_type.strip())\n",
    "\n",
    "        #for all floating values\n",
    "        if data_type in [\"score\", \"quantity\", \"value\",\"tally\",\"count\" , \"total\",\"sum\",\"measurement\",\"digits\",\"estimate\",\"metric\",\"numerical\",\"portion\",\"magnitude\",\"index\",\"volume\",\"number of\",\"amount\",\"discount\"]:\n",
    "            min_value, max_value = get_random_int_range()\n",
    "            data_generators[data_type] = lambda: fake.random_int(min=min_value, max=max_value)\n",
    "\n",
    "        # for all floating values\n",
    "        if data_type in [\"rate\"]:\n",
    "            min_value_f , max_value_f = get_random_float_range()\n",
    "            data_generators[data_type] = lambda: fake.random_float(min=min_value_f, max=max_value_f)\n",
    "            \n",
    "            \n",
    "    data = generate_data(data_types, num_rows)\n",
    "\n",
    "    create_csv(file_name, headers, data)\n",
    "    print(f\"CSV file '{file_name}.csv' generated successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
